{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.4 Classification Comparison.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlc2295/DSIRiverProject/blob/master/1_4_Classification_Comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6EG6rDSr62T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "de00b511-9d87-4e64-f2d8-be34b9a8beaf"
      },
      "source": [
        "import ee\n",
        "from IPython.display import Image\n",
        "\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=ZffDomER5DeIYZBnch9AxIpapbRIlE4tWGdEGe1BWOY&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/2wH_5G2DYT1qFMzsKYqdUd27iWaIQXGj5Do-ZQHV31uErqmVN8KnAXI\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMRF6lRtOYeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ee.Initialize()\n",
        "\n",
        "def get_images(path_list, row_list, satellite, start_date, end_date, max_cloud_percentage):\n",
        "  coll = ee.ImageCollection(satellite).filterDate(start_date, end_date)\\\n",
        "            .filter(ee.Filter.inList('WRS_PATH', path_list))\\\n",
        "            .filter(ee.Filter.inList('WRS_ROW', row_list))\\\n",
        "            .filter(ee.Filter.lt('CLOUD_COVER', max_cloud_percentage))\n",
        "  image_ids = list(map(lambda x: x['id'], coll.getInfo()['features']))\n",
        "\n",
        "  images = list(map(lambda x: ee.Image(x), image_ids))\n",
        "  return images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2NZI7QnxUJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "195b0a52-68a4-4755-b535-fc468f0de61a"
      },
      "source": [
        "'''\n",
        "Functions needed to display images and features/featurecollections are given here. \n",
        "These functions are all from other sources. Mostly from google tutorials.\n",
        "'''\n",
        "!pip install geojson\n",
        "!pip install pygeoj\n",
        "import geojson\n",
        "import json\n",
        "import pygeoj\n",
        "import numpy as np\n",
        "\n",
        "import folium\n",
        "\n",
        "# Define a method for displaying Earth Engine image tiles to folium map.\n",
        "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
        "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
        "  folium.raster_layers.TileLayer(\n",
        "    tiles = map_id_dict['tile_fetcher'].url_format,\n",
        "    attr = \"Map Data Â© Google Earth Engine\",\n",
        "    name = name,\n",
        "    overlay = True,\n",
        "    control = True\n",
        "  ).add_to(self)\n",
        "\n",
        "# Add EE drawing method to folium.\n",
        "folium.Map.add_ee_layer = add_ee_layer\n",
        "\n",
        "#@title Mapdisplay: Display GEE objects using folium.\n",
        "def Mapdisplay(center, dicc, Tiles=\"OpensTreetMap\",zoom_start=10):\n",
        "    '''\n",
        "    :param center: Center of the map (Latitude and Longitude).\n",
        "    :param dicc: Earth Engine Geometries or Tiles dictionary\n",
        "    :param Tiles: Mapbox Bright,Mapbox Control Room,Stamen Terrain,Stamen Toner,stamenwatercolor,cartodbpositron.\n",
        "    :zoom_start: Initial zoom level for the map.\n",
        "    :return: A folium.Map object.\n",
        "    '''\n",
        "    mapViz = folium.Map(location=center,tiles=Tiles, zoom_start=zoom_start)\n",
        "    for k,v in dicc.items():\n",
        "      if ee.image.Image in [type(x) for x in v.values()]:\n",
        "        folium.TileLayer(\n",
        "            tiles = v[\"tile_fetcher\"].url_format,\n",
        "            attr  = 'Google Earth Engine',\n",
        "            overlay =True,\n",
        "            name  = k\n",
        "          ).add_to(mapViz)\n",
        "      else:\n",
        "        folium.GeoJson(\n",
        "        data = v,\n",
        "        name = k\n",
        "          ).add_to(mapViz)\n",
        "    mapViz.add_child(folium.LayerControl())\n",
        "    return mapViz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geojson in /usr/local/lib/python3.6/dist-packages (2.5.0)\n",
            "Requirement already satisfied: pygeoj in /usr/local/lib/python3.6/dist-packages (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O04c-IIDOmCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create list of images from location\n",
        "\n",
        "import ee.mapclient\n",
        "\n",
        "#image = np.array([ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318')])\n",
        "path = [44]\n",
        "row = [34]\n",
        "satellite = 'LANDSAT/LC08/C01/T1_TOA'\n",
        "start_date = '2017-03-18'\n",
        "end_date = '2018-03-18'\n",
        "cc = 10\n",
        "image_list = get_images(path, row, satellite, start_date, end_date, cc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHsS38lWAFwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sfsite = ee.Geometry.Polygon([[-123.59202891324108,38.53717638470941],[-120.70262461636608,37.004492952240454],[-120.70262461636608,38.53717638470941],[-123.59202891324108,37.004492952240454]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6sL1pFWG4z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training = inputimg.sample({'region': nycsite, 'scale': 30.0, 'numPixels': 5000});\n",
        "def trained_cluster (inputimg):\n",
        "  training = inputimg.sample(region = sfsite, scale = 30.0, numPixels = 5000) #Training is based on 5000 randomly chosen pizels from within NYC area\n",
        "  numClusters = 2 #Number of clusters, I suspect. I think this should correspond to land and water.\n",
        "  clusterer = ee.Clusterer.wekaKMeans(numClusters).train(training) #Not sure what wekaMeans is - just the code used in the GEE tutorial\n",
        "  return clusterer\n",
        "\n",
        "def classify (inputimg):\n",
        "  training = inputimg.sample(region = sfsite, scale = 30.0, numPixels = 5000) #Training is based on 5000 randomly chosen pizels from within NYC area\n",
        "  numClusters = 2 #Number of clusters, I suspect. I think this should correspond to land and water.\n",
        "  clusterer = ee.Clusterer.wekaKMeans(numClusters).train(training) #Not sure what wekaMeans is - just the code used in the GEE tutorial\n",
        "  result = inputimg.cluster(clusterer) #Clustered result\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsHH5rZQUjxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Supervised Classification starts here\n",
        "\n",
        "#Import polygons for supervised classification\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofQuNgj1Upkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "9a8db3ba-e844-497d-ed03-f98d3c65b7d1"
      },
      "source": [
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1Gf4TqCciu4LZFZ7VQBaaZlBpIrBpyZ1l' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "\n",
        "with open(fname, 'r') as f:\n",
        "  print(f.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: water2.json, id: 1cz2TK_LMBLVBxVmhuEpE3kr9bgkujoGQ\n",
            "downloading to /root/data/water2.json\n",
            "title: water1.json, id: 1n4WrjynqhBpN9WtkNwuP_XcaPLxxBH7x\n",
            "downloading to /root/data/water1.json\n",
            "title: nonwater2.json, id: 1mb8W8iHemXIm-nVddExrZ4ejDQglo3RP\n",
            "downloading to /root/data/nonwater2.json\n",
            "title: nonwater1.json, id: 1E0MJWaY9vwxk3RkTCx0PAYm0l4bae4k0\n",
            "downloading to /root/data/nonwater1.json\n",
            "{\"type\":\"FeatureCollection\",\"features\":[\n",
            "{\"type\":\"Feature\",\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-122.42123859839,37.7490213426433,0],[-122.418823285194,37.7442911094521,0],[-122.418050993777,37.7429443091202,0],[-122.413332130966,37.7410214428332,0],[-122.412616460707,37.7410252826137,0],[-122.410672628798,37.741312986586,0],[-122.410519780595,37.7414333300924,0],[-122.408674015725,37.7436859960884,0],[-122.408461803442,37.7442934196917,0],[-122.408453225454,37.7447010810645,0],[-122.408436112952,37.7454381757864,0],[-122.42123859839,37.7490213426433,0]]]},\"properties\":{\"name\":\"nonwater1\",\"tessellate\":true}}\n",
            "]}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxaQdODTU9nD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "04bf860e-e167-43a7-f0d3-ce8b3c1c95dd"
      },
      "source": [
        "jsonfiles = ['water1.json','water2.json','nonwater1.json','nonwater2.json']\n",
        "classalloc = [1, 1, 0, 0];\n",
        "\n",
        "coords_dict = {}\n",
        "ee_dict = {}\n",
        "randomPts_dict = {}\n",
        "features_dict = {}\n",
        "\n",
        "n = 0\n",
        "for jsonfile in jsonfiles:\n",
        "    jsonfilepath = '/root/data/'+ jsonfile\n",
        "    with open(jsonfilepath) as f:\n",
        "        data = geojson.load(f)\n",
        "\n",
        "    #creating a dictionary of coordinates\n",
        "    coords_dict[jsonfile + 'coords'] = np.array(data['features'][0]['geometry']['coordinates'][0])[:,0:2].tolist()\n",
        "    \n",
        "    #creating a polygon from coordinate list\n",
        "    ee_dict[jsonfile + 'ee'] = ee.Geometry.Polygon(coords_dict[jsonfile + 'coords'])\n",
        "    \n",
        "    \n",
        "    #randomPoints = ee.FeatureCollection.randomPoints(region=ee_dict[jsonfile + 'ee'],points=100, {'name': jsonfile, 'landcover': classalloc[n]})\n",
        "    randomPoints = ee.FeatureCollection.randomPoints(region=ee_dict[jsonfile + 'ee'],points=30)\n",
        "    \n",
        "    def addProp(feature):\n",
        "      return feature.set({'landcover': classalloc[n]})\n",
        "\n",
        "    randomPoints = randomPoints.map(addProp) #This is to add a property named\n",
        "    \n",
        "    #randomPts_dict[jsonfile+'Pts'] = ee.Feature(ee.Geometry.MultiPoint(ee.List(coords_dict[jsonfile + 'coords'])), \n",
        "    #                                            {'name': jsonfile, 'class': classalloc[n]})\n",
        "    \n",
        "    randomPts_dict[jsonfile+'Pts'] = randomPoints\n",
        "    \n",
        "    \n",
        "    \n",
        "    #randomPts_dict[jsonfile + 'rdnmPts'] = ee.FeatureCollection.randomPoints(ee_dict[jsonfile + 'ee'], 100)\n",
        "    features_dict[jsonfile + 'feature'] = ee.Feature(ee_dict[jsonfile + 'ee'], {'name': jsonfile, 'landcover': classalloc[n]})\n",
        "\n",
        "    n = n+1\n",
        "\n",
        "'''\n",
        "The individual features are combined as shown below to create a feature collection.\n",
        "\n",
        "You can get some information about the features in the collection using commands as shown below.\n",
        "'''\n",
        "sfFC = ee.FeatureCollection(list(features_dict.values()))\n",
        "\n",
        "sfFCpts = ee.FeatureCollection(list(randomPts_dict.values()))\n",
        "\n",
        "fc = ee.FeatureCollection([])\n",
        "for x in randomPts_dict.keys():\n",
        "    #print(x) #I had used this to make sure the loop was okay\n",
        "    fc = fc.merge(randomPts_dict[x])\n",
        "\n",
        "\n",
        "print(sfFC.size().getInfo())\n",
        "\n",
        "print(type(sfFC.getInfo()))\n",
        "\n",
        "print(sfFC.getInfo()['features'][3]['properties'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "<class 'dict'>\n",
            "{'landcover': 0, 'name': 'nonwater2.json'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymlFoWA9Vd9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Second step in any supervised classification process - training using the training data. The corresponding\n",
        "code in Google EE tutorial is as follows:\n",
        "// Get the values for all pixels in each polygon in the training.\n",
        "var training = image.sampleRegions({\n",
        "  // Get the sample from the polygons FeatureCollection.\n",
        "  collection: polygons,\n",
        "  // Keep this list of properties from the polygons.\n",
        "  properties: ['class'],\n",
        "  // Set the scale to get Landsat pixels in the polygons.\n",
        "  scale: 30\n",
        "});\n",
        "\n",
        "The code is in javascript. I had to convert it to Python. Mistakes could be created/transmitted because of this\n",
        "translation\n",
        "'''\n",
        "bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']\n",
        "#bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "\n",
        "def trained_classifier (image):\n",
        "  training_image = image.select(bands).sampleRegions(collection =  fc, properties = ['landcover'], scale = 30.0)\n",
        "  #print(training.geometry().getInfo()['type'])\n",
        "\n",
        "  '''\n",
        "  We can view feature collections using Mapdisplay, the function we encountered earlier. THe way to do it is as follows:\n",
        "  Mapdisplay(center,dicc={'poly1':hudson02ee.getInfo(),'poly2':hudson01ee.getInfo(), 'poly3': Astoria01ee.getInfo(), 'poly4': Bronx01ee.getInfo()},zoom_start=2)\n",
        "  '''\n",
        "\n",
        "  training_centroid = training_image.geometry().centroid().getInfo()['coordinates']\n",
        "  training_centroid.reverse()\n",
        "\n",
        "  '''\n",
        "  training_centroid is also a featurecollection but different from nycFC. Try print(training.size().getInfo()) - \n",
        "  you'll see that the size is about 20000, not 4. Since I cannot display training, I think there must be a mistake \n",
        "  right here. Need to rectify this - understand image.sampleRegions better before proceeding further.\n",
        "  '''\n",
        "  #Train the classifier.\n",
        "  #var trained = classifier.train(training, 'class', bands);\n",
        "  #trained = classifier.train(training, 'landcover', bands);\n",
        "  trained = ee.Classifier.smileCart().train(training_image, 'landcover', bands)\n",
        "  #print(type(trained))\n",
        "  return trained\n",
        "\n",
        "def training (image):\n",
        "  training_image = image.select(bands).sampleRegions(collection =  fc, properties = ['landcover'], scale = 30.0)\n",
        "  #print(training.geometry().getInfo()['type'])\n",
        "\n",
        "  '''\n",
        "  We can view feature collections using Mapdisplay, the function we encountered earlier. THe way to do it is as follows:\n",
        "  Mapdisplay(center,dicc={'poly1':hudson02ee.getInfo(),'poly2':hudson01ee.getInfo(), 'poly3': Astoria01ee.getInfo(), 'poly4': Bronx01ee.getInfo()},zoom_start=2)\n",
        "  '''\n",
        "\n",
        "  training_centroid = training_image.geometry().centroid().getInfo()['coordinates']\n",
        "  training_centroid.reverse()\n",
        "\n",
        "  '''\n",
        "  training_centroid is also a featurecollection but different from nycFC. Try print(training.size().getInfo()) - \n",
        "  you'll see that the size is about 20000, not 4. Since I cannot display training, I think there must be a mistake \n",
        "  right here. Need to rectify this - understand image.sampleRegions better before proceeding further.\n",
        "  '''\n",
        "  #Train the classifier.\n",
        "  #var trained = classifier.train(training, 'class', bands);\n",
        "  #trained = classifier.train(training, 'landcover', bands);\n",
        "  trained = ee.Classifier.smileCart().train(training_image, 'landcover', bands)\n",
        "  #print(type(trained))\n",
        "   #Classify the image.\n",
        "  '''\n",
        "  This is the step at which the code is failing. If I try to interrogate classified in anyway, the computation is \n",
        "  never completed. For example, if I did classified.getInfo(), an asterix * would appear next to the cell, never to \n",
        "  finish.\n",
        "  '''\n",
        "  classified = image.select(bands).classify(trained)\n",
        "  return classified\n",
        "\n",
        "  #print(type(classified))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpSCf4gsVxlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "5b233012-62f4-4498-a192-82f84ebd3087"
      },
      "source": [
        "#Comparison\n",
        "for image in image_list:\n",
        "  unsupervised = trained_cluster(image)\n",
        "  supervised = trained_classifier(image)\n",
        "\n",
        "  #Confusion matrix representing resubstitution accuracy for unsupervised\n",
        "  #Reduced number of clusters for unsupervised because confusion matrix works better for 2 classes.\n",
        "  trainAccuracy = unsupervised.confusionMatrix()\n",
        "  print('Resubstitution error matrix: ', trainAccuracy)\n",
        "  print('Training overall accuracy: ', trainAccuracy.accuracy())\n",
        "  \n",
        "  #Confusion matrix representing resubstitution accuracy for supervised\n",
        "  trainAccuracy = supervised.matchingMatrix()\n",
        "  print('Resubstitution error matrix: ', trainAccuracy)\n",
        "  print('Training overall accuracy: ', trainAccuracy.accuracy())\n",
        "\n",
        "  #Get a confusion matrix representing expected accuracy. Not sure if we can do \n",
        "  #this because while MODIS satellite has \"Land_Cover_Type_1,\" LANDSAT does not.\n",
        "  #testAccuracy = validated.errorMatrix('Land_Cover_Type_1', 'classification')\n",
        "  #print('Validation error matrix: ', testAccuracy)\n",
        "  #print('Validation overall accuracy: ', testAccuracy.accuracy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-5aa0e7b06378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#Confusion matrix representing resubstitution accuracy for unsupervised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#Reduced number of clusters for unsupervised because confusion matrix works better for 2 classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mtrainAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsupervised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resubstitution error matrix: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainAccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training overall accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainAccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Clusterer' object has no attribute 'confusionMatrix'"
          ]
        }
      ]
    }
  ]
}